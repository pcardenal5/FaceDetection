{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "## Unstructured Data Image proyect\n",
    "### By\n",
    "- Juan Miguel Ramos Pugnaire\n",
    "- Juan Ortega Ortega\n",
    "- Pablo Cardenal\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "### Solutions\n",
    "\n",
    "__Project Index__\n",
    "<div>\n",
    "    <ol>Data Extraction</ol>\n",
    "    <ol>Data Preparation</ol>\n",
    "    <ol>Interface development</ol>\n",
    "    <ol>Training & Test</ol>\n",
    "    <ol>Parameter Tuning</ol>\n",
    "    <ol>Results</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "training_files=\"./training\"\n",
    "test_files=\"./test\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Extraction \n",
    "*Generating data for the model*  \n",
    "[Enter explanation]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation \n",
    "*Altering the training and test*  \n",
    "Parameters in data preparation:\n",
    "- directory : Location of the Directory\n",
    "- labels=\"inferred\": labels of the photos stated by the directory structure\n",
    "- label_mode= \"categorical\" : Type of label\n",
    "- class_names= [\"JuanM\",\"JuanO\",\"Pablo\",\"pepe\"]: Only valid if label is inferred\n",
    "- color_mode= \"grayscale\", \"rgb\", \"rgba\" depending on channel\n",
    "- batch_size=32 : Number of images tat are proccessed in each iteration\n",
    "- image_size=(256,256)(default): Size to resize the image when rea from disk-> Un batchsize pequeño es más preciso pero más lento \n",
    "- shuffle=True(default)\n",
    "- seed=optional \n",
    "- validation_split= 0.1 :Fraction of data reserved for validation\n",
    "- subset: only used when valdation is set\n",
    "- interpolation=bilinear(default) : used for resizing images \n",
    "- crop_to_aspect_ratio: True para redimensión recortando imagen, False para redimensión con deformidad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, filename: str, model_name: str):\n",
    "    \"\"\"Saves the model to an .h5 file and the model name to a .json file.\n",
    "\n",
    "    Args:\n",
    "        filename: Relative path to the file without the extension.\n",
    "\n",
    "    \"\"\"\n",
    "    # Save Keras model\n",
    "    model.save(filename + '.h5')\n",
    "\n",
    "    # Save base model information\n",
    "    with open(filename + '.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(model_name, f, ensure_ascii=False, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "#--------------------- Data Preprocessing --------------------#\n",
    "\n",
    "#feature training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        # reducing/normalizing the pixels\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "#connecting the image augmentation tool to our dataset\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "        './training',\n",
    "        #final size of the images that will be fed into the ann\n",
    "        target_size=(640, 480),\n",
    "        # number of images that we want to have in each batch\n",
    "        batch_size=32,\n",
    "        # we have binary classification --> binary class mode\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "#only rescaling but no transformations\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#connecting to the test data\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        './test',\n",
    "        target_size=(640, 480),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "print(test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Interface develpment\n",
    "*Interface programming*  \n",
    "[Enter explanation]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training & Test\n",
    "*First model structure*  \n",
    "[Enter explanation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- Building CNN --------------------#\n",
    "# initializing CNN as sequential layers\n",
    "from tf.keras.callbacks import EarlyStopping\n",
    "def create_model():\n",
    "        \n",
    "    cnn = tf.keras.models.Sequential()\n",
    "\n",
    "    # Step 1: Convolution to get the Feature Map\n",
    "    cnn.add(tf.keras.layers.Conv2D(filters= 210 , kernel_size = 2, activation = 'relu', input_shape=[640,480,3]))\n",
    "    # filters: output feature map\n",
    "    # kernel_size: size of the feature detector\n",
    "    # strides: step size from one filter to the next default is 1\n",
    "    # Step 2: Max Pooling\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 ,strides=2))\n",
    "    #adding a second convolutional layer\n",
    "    cnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 ,strides=2))\n",
    "    #adding a second convolutional layer\n",
    "    cnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 ,strides=2))\n",
    "    #adding a second convolutional layer\n",
    "    cnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 ,strides=2))\n",
    "    # Step 3: Flattening\n",
    "    cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Step 4: Full Connection\n",
    "    cnn.add(tf.keras.layers.Dense(units = 256, activation = 'relu'))\n",
    "\n",
    "    # Step 5: Output Layer\n",
    "    cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "    return cnn\n",
    "\n",
    "#--------------------- Training the CNN --------------------#\n",
    "#compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#training the CNN on the training set and evaluating it on the test set\n",
    "cnn.fit(x = train_set, validation_data = test_set, epochs = 25)\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=10)\n",
    "history = model.fit(X, y, validation_split=0.33, epochs=200, batch_size=15, verbose=0, callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Parameter tuning\n",
    "*Detail parameters and how they change*  \n",
    "[Enter explanation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Final Results\n",
    "*Check final results and future implementations*  \n",
    "[Enter explanation]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DtNoStructENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
